
免密码登录
ssh-keygen -t dsa -P '' -f ~/.ssh/id_dsa
cat ~/.ssh/id_dsa.pub >> ~/.ssh/authorized_keys

标签----------------------

hdfs
http://hadoop1:50070/dfshealth.jsp

yarn
http://hadoop1:8088/cluster/cluster

Storm-master
http://hadoop1:8080/

Storm-shell
http://hadoop1:4040/
---------------------------------

start-dfs.sh
start-yarn.sh

hdfs dfs -mkdir /in
hdfs dfs -ls /

hadoop dfs -copyFromLocal /data/in/ /in
hadoop jar share/hadoop/mapreduce/hadoop-mapreduce-examples-2.2.0.jar wordcount /in /out
hadoop jar share/hadoop/mapreduce/hadoop-mapreduce-examples-2.2.0.jar pi 2 2 

------------------------------
HDFS配置
hadoop-env.sh
core-site.xml
hdfs-site.xml

map-reduce配置
mapred-env.sh
mapred-site.xml

yarn配置
yarn-site.xml

masters & slaves 文件
---------------------------------
spark配置
spark-env.sh
slaves

--------------------------
和yarn集成
参照 http://my.oschina.net/u/1169079/blog/292435
export HADOOP_HOME= /home/hadoop/hadoop-2.0.0-cdh4.5.0
export HADOOP_CONF_DIR= $HADOOP_HOME/etc/hadoop
SPARK_EXECUTOR_INSTANCES=2
SPARK_EXECUTOR_CORES=1
SPARK_EXECUTOR_MEMORY=400M
SPARK_DRIVER_MEMORY=400M
SPARK_YARN_APP_NAME="Spark 1.0.0"
---------------------------------
start-dfs.sh
NameNode
DataNode
SecondaryNameNode

start-yarn.sh
NodeManager
ResourceManager

start-spark-all.sh
Master
Worker




----------------------------------------

val lines = sc.textFile("README.md")   
lines.count()   
lines.first()   
val pythonLines = lines.filter(line => line.contains("Python"))   
 
scala> lines.first()  

-----------------------------------------

让更改的名字在不重启机器下生效

# hostname yourname


----------------------------------------
yarn logs -applicationId <applicationId>


hbase--------------------------

http://www.abcn.net/2014/07/lighting-spark-with-hbase-full-edition.html

spark-submit --master spark://hadoop1:7077 --class spark.examples.SparkWordCount2 --name SparkWordCount SparkWordCount.jar
spark-submit --class spark.examples.SparkWordCount2 --name SparkWordCount SparkWordCount.jar


spark-submit --driver-class-path "/usr/hbase/hbase-0.96.2-hadoop2/lib/*"  --class spark.examples.Tristan02 --name Tristan02 SparkWordCount.jar

spark-shell --driver-class-path "/usr/hbase/hbase-0.96.2-hadoop2/lib/*"


